#### Here's a **complete step-by-step guide** to install **Boto3**, authenticate it using AWS Console and CLI, and set up all **prerequisites** â€” essential for any DevOps Engineer working with Python automation on AWS.

---

## âœ… 1. What is Boto3?

**Boto3** is the **official AWS SDK for Python**, used to automate AWS services like EC2, S3, IAM, etc., using Python scripts.

---

## ğŸ§° 2. Prerequisites

Before you install and use Boto3, ensure you have:

* âœ… Python 3.6+
* âœ… pip (Python package installer)
* âœ… AWS account & IAM credentials
* âœ… AWS CLI installed and configured (for easier setup)

---

## ğŸ”§ 3. Installing Python and pip (if not already installed)

### On Ubuntu/Debian:

```bash
sudo apt update
sudo apt install python3 python3-pip -y
```

### On Amazon Linux/RHEL:

```bash
sudo yum install python3 -y
```

### Verify:

```bash
python3 --version
pip3 --version
```

---

## ğŸ“¦ 4. Installing Boto3

```bash
pip3 install boto3
```

### Verify:

```bash
python3 -c "import boto3; print(boto3.__version__)"
```

---

## ğŸ” 5. Authentication with AWS (Required to use Boto3)

You can authenticate in multiple ways. The two most common ways:

---

### âœ… A. Using AWS CLI (Recommended)

### Step 1: Install AWS CLI

#### Ubuntu/Debian:

```bash
sudo apt install awscli -y
```

#### Amazon Linux/RHEL:

```bash
sudo yum install awscli -y
```

### Step 2: Configure AWS CLI with Access Key

Go to AWS Console â†’ IAM â†’ Users â†’ Select your user â†’ **Security Credentials** â†’ Create access key.

Then:

```bash
aws configure
```

Enter:

```
AWS Access Key ID:     <from console>
AWS Secret Access Key: <from console>
Default region name:   us-east-1  (or as per your region)
Default output format: json
```

This stores the credentials in:

* `~/.aws/credentials`
* `~/.aws/config`

Boto3 **automatically uses these files**.

---

### âœ… B. Using Environment Variables (optional/alternative)

Set temporary credentials for session use:

```bash
export AWS_ACCESS_KEY_ID="your-access-key-id"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_DEFAULT_REGION="us-east-1"
```

To use session tokens (e.g., with MFA or roles):

```bash
export AWS_SESSION_TOKEN="your-session-token"
```

Boto3 will use these if set.

---

## ğŸ§ª 6. Testing Boto3 Connection

### Simple script to list S3 buckets:

```python
import boto3

s3 = boto3.client('s3')
response = s3.list_buckets()

print("S3 Buckets:")
for bucket in response['Buckets']:
    print(f"  - {bucket['Name']}")
```

Run it:

```bash
python3 list_s3.py
```

If authentication is correct, you'll see your S3 buckets.

---

## ğŸ”„ 7. Optional: Role-based Authentication (EC2, Lambda, etc.)

If you're running your Python code inside an **EC2 instance** or **Lambda**, attach an IAM role and **do not use keys at all**. Boto3 will **automatically pick credentials** from the EC2 metadata.

---

## ğŸ§¹ 8. Cleaning Up / Switching Profiles

* Use `aws configure --profile <name>` to manage multiple profiles.
* Use `boto3.Session(profile_name='dev')` to use a specific profile in code.

---
#### Let's deep dive into **Role-Based Authentication using IAM Roles** for **EC2, Lambda, and other AWS services** â€” the most secure and DevOps-recommended way to authenticate AWS SDKs like **Boto3**, without using access keys.

---

## âœ… What Is Role-Based Authentication?

Instead of using **hardcoded access keys**, AWS services like **EC2**, **Lambda**, **ECS**, etc., can assume an **IAM Role** that has permissions to perform AWS actions.

> ğŸ” Boto3 will **automatically detect** and use the IAM Role attached to the instance or function â€” **no access key configuration is required**.

---

## ğŸ§° Use Case Example: EC2 Instance with Boto3 Script

---

### âœ… Step 1: Create an IAM Role

1. Go to **AWS Console â†’ IAM â†’ Roles**
2. Click **Create Role**
3. Choose **Trusted Entity Type**: `AWS Service`
4. Select **EC2** as the service
5. Attach a policy like:

   * `AmazonS3ReadOnlyAccess` (or your custom policy)
6. Give it a name like `DevOpsEC2Role`
7. Finish creation

---

### âœ… Step 2: Attach Role to EC2 Instance

1. Go to **EC2 â†’ Instances**
2. Select your instance â†’ **Actions â†’ Security â†’ Modify IAM Role**
3. Attach the IAM role `DevOpsEC2Role`

---

### âœ… Step 3: SSH into EC2 and Install Boto3 (if needed)

```bash
sudo yum install python3 -y   # Amazon Linux
pip3 install boto3
```

> **NO need to run `aws configure`** â€” credentials are retrieved via EC2 metadata.

---

### âœ… Step 4: Run Boto3 Script

Example: list S3 buckets

```python
# list_s3.py
import boto3

s3 = boto3.client('s3')
buckets = s3.list_buckets()

print("Buckets:")
for b in buckets['Buckets']:
    print(" -", b['Name'])
```

```bash
python3 list_s3.py
```

âœ… **If IAM role has the correct permissions**, it will run successfully.

---

## ğŸ“¦ How Boto3 Works Behind the Scenes

Boto3 checks credentials in this order:

1. **Environment variables**
2. **Shared credential file** (`~/.aws/credentials`)
3. **IAM role for EC2/Lambda/ECS** â†’ This uses **Instance Metadata Service (IMDS)**

```http
http://169.254.169.254/latest/meta-data/iam/security-credentials/
```

---

## âœ… Use in Lambda

1. Go to **Lambda â†’ Create Function**
2. Under **Permissions**, select **"Create a new role with basic Lambda permissions"**
3. Attach additional policies like `AmazonS3ReadOnlyAccess`
4. In your Lambda function:

```python
import boto3

s3 = boto3.client('s3')

def lambda_handler(event, context):
    buckets = s3.list_buckets()
    return [b['Name'] for b in buckets['Buckets']]
```

âœ… Lambda automatically assumes the execution role. No access keys or config needed.

---

## ğŸ›¡ï¸ Security Benefits

* âœ… No hardcoded secrets
* âœ… Automatically rotated credentials
* âœ… Least-privilege principle enforced via IAM
* âœ… Easier to audit via CloudTrail

---

## ğŸ§ª Test Role Access (Optional Debug)

From EC2:

```bash
curl http://169.254.169.254/latest/meta-data/iam/security-credentials/
```

Youâ€™ll see the IAM role name â†’ use it in scripts if needed for logging/debugging.

---


