# **AWS SDK Pagination & Error Handling using `boto3`** 

---

# 📘 Part 1: **Pagination in Boto3**

## ✅ Why Pagination?

Most AWS API responses (like listing EC2, S3, Lambda) return **limited results** (e.g. 1000 items max).
To get **all results**, you need to **paginate** through them.

---

## 🔧 Example 1: List All S3 Buckets (No Pagination Needed)

```python
import boto3

s3 = boto3.client('s3')

response = s3.list_buckets()

for bucket in response['Buckets']:
    print(bucket['Name'])
```

✅ Here, pagination is not needed because the result is small.

---

## 🔁 Example 2: Paginate EC2 Instances

### Without Pagination (only first page):

```python
ec2 = boto3.client('ec2')
response = ec2.describe_instances()
```

### ✅ With Pagination:

```python
import boto3

ec2 = boto3.client('ec2')
paginator = ec2.get_paginator('describe_instances')

for page in paginator.paginate():
    for reservation in page['Reservations']:
        for instance in reservation['Instances']:
            print("Instance ID:", instance['InstanceId'])
```

### 🔍 Explanation:

* `get_paginator('describe_instances')` returns a **Paginator object**.
* `paginate()` returns an **iterator of pages**.
* We loop through each page and extract data.

---

## 🔁 Example 3: Paginate S3 Objects

```python
import boto3

s3 = boto3.client('s3')
bucket_name = 'my-bucket'

paginator = s3.get_paginator('list_objects_v2')

for page in paginator.paginate(Bucket=bucket_name):
    for obj in page.get('Contents', []):
        print("S3 Object:", obj['Key'])
```

---

## ✅ Best Practice: Use Pagination for:

| Service    | Operation                  |
| ---------- | -------------------------- |
| EC2        | `describe_instances`       |
| S3         | `list_objects_v2`          |
| Lambda     | `list_functions`           |
| IAM        | `list_users`, `list_roles` |
| CloudWatch | `describe_alarms`          |
| DynamoDB   | `scan`, `query`            |

---

# 📘 Part 2: **Error Handling in Boto3**

### 🔥 Why Important?

* AWS APIs can **fail**: missing permissions, network issues, throttling, etc.
* Good error handling prevents crashes and adds retry logic.

---

## ✅ Basic Error Handling Example

```python
import boto3
from botocore.exceptions import ClientError

s3 = boto3.client('s3')

try:
    s3.upload_file('file.txt', 'non-existent-bucket', 'file.txt')
except ClientError as e:
    print("Error:", e.response['Error']['Message'])
```

---

## 🔍 Types of Exceptions in Boto3

| Exception Type            | Use When...                       |
| ------------------------- | --------------------------------- |
| `ClientError`             | AWS API returns an error response |
| `NoCredentialsError`      | AWS credentials are missing       |
| `EndpointConnectionError` | AWS service is unreachable        |
| `ParamValidationError`    | Invalid parameters passed         |
| `BotoCoreError`           | Base class for all Boto3 errors   |

---

## 🛡️ Example: Handling Multiple Exceptions

```python
import boto3
from botocore.exceptions import ClientError, NoCredentialsError, EndpointConnectionError

s3 = boto3.client('s3')

try:
    s3.download_file('my-bucket', 'file.txt', 'downloaded.txt')
except NoCredentialsError:
    print("❌ No AWS credentials found.")
except EndpointConnectionError:
    print("❌ Could not connect to AWS endpoint.")
except ClientError as e:
    error_code = e.response['Error']['Code']
    print(f"❌ ClientError [{error_code}]: {e.response['Error']['Message']}")
except Exception as e:
    print("❌ Unknown error occurred:", str(e))
```

---

## 🔄 Example: Retry Logic (Simple)

```python
import time
from botocore.exceptions import ClientError

def safe_upload(s3_client, file, bucket, key, retries=3):
    for i in range(retries):
        try:
            s3_client.upload_file(file, bucket, key)
            print("✅ Upload successful")
            break
        except ClientError as e:
            print(f"Attempt {i+1} failed:", e.response['Error']['Message'])
            time.sleep(2)
    else:
        print("❌ Upload failed after retries")
```

---

# 🧪 Real-World Use Case: Lambda Triggered by S3, Handles Throttling

```python
def lambda_handler(event, context):
    import boto3
    from botocore.exceptions import ClientError

    s3 = boto3.client('s3')
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']

    try:
        response = s3.get_object(Bucket=bucket, Key=key)
        content = response['Body'].read().decode()
        print("File Content:", content)
    except ClientError as e:
        if e.response['Error']['Code'] == 'Throttling':
            print("Throttling occurred. Consider retrying.")
        else:
            raise
```

---

# ✅ Summary

## 🔁 **Pagination:**

* Use `get_paginator('api_call')`
* Iterate using `.paginate()`
* Handles large results safely

## 🛡️ **Error Handling:**

* Catch `ClientError`, `NoCredentialsError`, `BotoCoreError`
* Print meaningful error messages
* Implement retries for robustness

---

